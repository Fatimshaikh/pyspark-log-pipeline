# PySpark Log Data Cleaning & Analytics Pipeline
**Bronze → Silver → Gold ETL Pipeline using PySpark**
## Project Overview

This project demonstrates a **real-world data engineering pipeline** for processing and analyzing log files using **PySpark**. The pipeline follows the **Bronze → Silver → Gold architecture**, commonly used in modern big data environments.

- **Bronze Layer:** Ingest raw logs (text files) and store as Parquet.  
- **Silver Layer:** Clean and structure the logs (parse timestamp, level, message; remove duplicates).  
- **Gold Layer:** Aggregate data for analytics (e.g., error counts, most frequent log levels).

The project showcases **PySpark skills, ETL pipelines, and data engineering best practices**.

## Tech Stack
- **Python 3.11+**  
- **PySpark 4.1.1 (with Hadoop 3.4 pre-built)**  
- **VS Code**   
- **Git & GitHub**  
